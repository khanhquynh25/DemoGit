{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA+XGOqCjCKkMtsGHXH/c4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhquynh25/DemoGit/blob/master/x%C4%91mgti%E1%BB%81n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xov5rQ4qFTQh",
        "outputId": "49d11da0-97a7-4df1-95eb-bbdefb14dc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 11 images belonging to 9 classes.\n",
            "Found 8 images belonging to 9 classes.\n",
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0909 - loss: 3.4734 - val_accuracy: 0.1250 - val_loss: 12.8968\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0909 - loss: 21.4994 - val_accuracy: 0.1250 - val_loss: 18.4340\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - accuracy: 0.2727 - loss: 16.5710 - val_accuracy: 0.0000e+00 - val_loss: 10.7912\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1818 - loss: 26.1486 - val_accuracy: 0.2500 - val_loss: 18.8111\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - accuracy: 0.4545 - loss: 16.4731 - val_accuracy: 0.2500 - val_loss: 21.8745\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step - accuracy: 0.3636 - loss: 13.1243 - val_accuracy: 0.2500 - val_loss: 23.5245\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step - accuracy: 0.1818 - loss: 28.4958 - val_accuracy: 0.2500 - val_loss: 23.2139\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - accuracy: 0.1818 - loss: 20.8760 - val_accuracy: 0.2500 - val_loss: 20.2754\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step - accuracy: 0.0000e+00 - loss: 33.8677 - val_accuracy: 0.2500 - val_loss: 14.9545\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - accuracy: 0.0000e+00 - loss: 30.4308 - val_accuracy: 0.2500 - val_loss: 9.7947\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659ms/step - accuracy: 0.1818 - loss: 24.6861 - val_accuracy: 0.0000e+00 - val_loss: 13.1177\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step - accuracy: 0.0000e+00 - loss: 37.5955 - val_accuracy: 0.0000e+00 - val_loss: 18.3339\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step - accuracy: 0.0909 - loss: 33.6930 - val_accuracy: 0.0000e+00 - val_loss: 21.3602\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - accuracy: 0.0000e+00 - loss: 33.4053 - val_accuracy: 0.0000e+00 - val_loss: 19.5877\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - accuracy: 0.1818 - loss: 33.7558 - val_accuracy: 0.0000e+00 - val_loss: 13.0404\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684ms/step - accuracy: 0.3636 - loss: 15.0011 - val_accuracy: 0.2500 - val_loss: 10.7171\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1818 - loss: 31.8329 - val_accuracy: 0.2500 - val_loss: 13.8388\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889ms/step - accuracy: 0.1818 - loss: 23.4185 - val_accuracy: 0.2500 - val_loss: 15.9712\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830ms/step - accuracy: 0.0909 - loss: 26.4745 - val_accuracy: 0.2500 - val_loss: 17.3635\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1818 - loss: 23.2178 - val_accuracy: 0.2500 - val_loss: 16.3542\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - accuracy: 0.1818 - loss: 18.0010 - val_accuracy: 0.2500 - val_loss: 15.3334\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step - accuracy: 0.0909 - loss: 17.3307 - val_accuracy: 0.2500 - val_loss: 12.3516\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - accuracy: 0.1818 - loss: 15.6142 - val_accuracy: 0.2500 - val_loss: 10.2687\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - accuracy: 0.3636 - loss: 11.3296 - val_accuracy: 0.0000e+00 - val_loss: 9.9458\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - accuracy: 0.3636 - loss: 8.2621 - val_accuracy: 0.0000e+00 - val_loss: 7.8736\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step - accuracy: 0.4545 - loss: 5.6709 - val_accuracy: 0.0000e+00 - val_loss: 7.1265\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step - accuracy: 0.5455 - loss: 6.5652 - val_accuracy: 0.0000e+00 - val_loss: 6.1438\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - accuracy: 0.1818 - loss: 8.2735 - val_accuracy: 0.0000e+00 - val_loss: 6.3370\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step - accuracy: 0.4545 - loss: 5.5223 - val_accuracy: 0.0000e+00 - val_loss: 6.0733\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - accuracy: 0.2727 - loss: 7.4720 - val_accuracy: 0.0000e+00 - val_loss: 5.9890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã train xong và lưu mô hình ANN tại: /content/drive/MyDrive/xacdinhmgt1/money_ann.h5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "\n",
        "# ================== 1. KẾT NỐI GOOGLE DRIVE ==================\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Thư mục chứa dataset trong Drive\n",
        "base_dir = \"/content/drive/MyDrive/xacdinhmgt1\"\n",
        "\n",
        "# ================== 2. TIỀN XỬ LÝ DỮ LIỆU ==================\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.5  # 20% dữ liệu làm validation\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# ================== 3. XÂY DỰNG MÔ HÌNH ANN ==================\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(img_size[0], img_size[1], 3)),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(train_generator.class_indices), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# ================== 4. COMPILE ==================\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# ================== 5. TRAIN ==================\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "# ================== 6. LƯU MÔ HÌNH VÀO DRIVE ==================\n",
        "save_path = \"/content/drive/MyDrive/xacdinhmgt1/money_ann.h5\"\n",
        "model.save(save_path)\n",
        "print(f\"✅ Đã train xong và lưu mô hình ANN tại: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Hàm dự đoán\n",
        "def predict_and_show(img):\n",
        "    img_resized = img.resize(img_size)   # resize về (128,128)\n",
        "    img_array = img_to_array(img_resized) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    preds = model.predict(img_array)\n",
        "    class_idx = np.argmax(preds)\n",
        "    confidence = np.max(preds)\n",
        "    label = labels[class_idx]\n",
        "\n",
        "    return f\"💵 Đây là mệnh giá: {label} nghìn\\n(Độ tin cậy: {confidence:.2f})\"\n",
        "\n",
        "# ================== CSS cho nền hồng + nút đỏ + chữ kết quả to/đậm ==================\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {background-color: #ffe6f0; font-family: Arial;}\n",
        "h1, h2, h3 {color: #cc0052; font-weight: bold;}\n",
        "label {color: #99003d; font-weight: bold;}\n",
        "button {background-color: #ff1a1a !important; color: white !important;\n",
        "        font-weight: bold; border-radius: 10px !important; padding: 10px 20px !important;}\n",
        ".output-textbox textarea {font-size: 22px !important; font-weight: bold !important; color: #cc0000;}\n",
        "\"\"\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_and_show,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"📷 Upload ảnh tiền\"),\n",
        "    outputs=gr.Textbox(label=\"📌 Kết quả dự đoán\"),\n",
        "    title=\"💵 Nhận diện mệnh giá tiền\",\n",
        "    description=\"Upload ảnh tiền để dự đoán mệnh giá (theo đơn vị nghìn).\",\n",
        "    css=custom_css\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "AMTeNNXCisge",
        "outputId": "8f5832c4-ff96-43d8-c66c-c8a2b3fb954e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b958e443fbf5d57cc2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b958e443fbf5d57cc2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Using existing dataset file at: .gradio/flagged/dataset3.csv\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
          ]
        }
      ]
    }
  ]
}